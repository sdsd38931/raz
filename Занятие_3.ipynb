{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdsd38931/raz/blob/main/%D0%97%D0%B0%D0%BD%D1%8F%D1%82%D0%B8%D0%B5_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4PJZou-EBki"
      },
      "source": [
        "Итак, перед тем, как браться за статистику, нужно:\n",
        "\n",
        "**1. Прочесть исходный файл и превратить его в структуру данных**\n",
        "\n",
        "К заданию прилагается файл в формате csv, где все значения разделены запятыми. Это наши исходные данные. Чтобы применить к ним все возможности языка Python и библиотеки Pandas, надо импортировать эту библиотеку и сохранить её в переменной. По сокращённому названию панельных данных (panel data), с которых начиналась Pandas, эту переменную принято называть pd:\n",
        "\n",
        "**import pandas as pd**\n",
        "\n",
        "Для чтения csv-файла в библиотеке Pandas есть готовая функция — метод **read_csv()**. Как и все методы, он вызывается записью через точку после имени своего объекта. В скобках указывается аргумент (параметр) метода. У read_csv() это имя файла с данными. Прочтение превращает файл в структуру данных DataFrame. Имя переменной, в которой эта структура данных сохраняется, чаще всего df либо отражает тематику данных:\n",
        "\n",
        "**df = pd.read_csv('music_log.csv')**\n",
        "\n",
        "**2. Посмотреть на данные**\n",
        "\n",
        "Вывести на экран таблицу и оценить данные:\n",
        "\n",
        "print(df)\n",
        "Как правило, таблица очень велика. Практичнее запросить определённое количество первых строк, методом head().\n",
        "\n",
        "**3. Оценить качество предподготовки**\n",
        "\n",
        "Нужно убедиться в том, что данные прошли предподготовку. По крайней мере, не должно быть пропусков и повторов. Пропущенные и неопределённые значения выявляет метод **isna()**, а суммарное количество таких значений — метод **sum()**.\n",
        "\n",
        "**print(df.isna().sum())**\n",
        "\n",
        "\n",
        "Повторяющиеся строки — дубликаты — выявляются методом **duplicated()** и подсчитываются тем же sum():\n",
        "\n",
        "**print(df.duplicated().sum())**\n",
        "Если возвращаются нули, всё хорошо — данные пригодны для исследования.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yssUNq_zEBkj"
      },
      "source": [
        "## Задача\n",
        "\n",
        "1. Загрузите таблицу **exoplanet_catalog**, содержащую данные о планетах за пределами Солнечной системы, или экзопланетах. Сформируйте из данной таблицы новый датасет под назанием **exoplanet**, коорая будет содердать стоблцы name, mass, radius, discovered. Проверьте, чтобы название всех столбцов было корректным, при необходмости измените названия.\n",
        "\n",
        "2. Удалите из получившейся таблица строки с нулевыми значениями.\n",
        "\n",
        "3. Убедитесь, что таблица не содержит ни пропущенных значений, ни дубликатов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "cI84Tc95EBkk",
        "outputId": "dae9b20e-d516-47b0-fe69-39da95d31162"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bc545482-fc0d-433e-87c0-4fae41d17a9c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bc545482-fc0d-433e-87c0-4fae41d17a9c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving exoplanet_catalog.csv to exoplanet_catalog.csv\n",
            "Index(['# name', 'planet_status', 'mass', 'mass_error_min', 'mass_error_max',\n",
            "       'mass_sini', 'mass_sini_error_min', 'mass_sini_error_max', 'radius',\n",
            "       'radius_error_min', 'radius_error_max', 'orbital_period',\n",
            "       'orbital_period_error_min', 'orbital_period_error_max',\n",
            "       'semi_major_axis', 'semi_major_axis_error_min',\n",
            "       'semi_major_axis_error_max', 'eccentricity', 'eccentricity_error_min',\n",
            "       'eccentricity_error_max', 'inclination', 'inclination_error_min',\n",
            "       'inclination_error_max', 'angular_distance', 'discovered', 'updated',\n",
            "       'omega', 'omega_error_min', 'omega_error_max', 'tperi',\n",
            "       'tperi_error_min', 'tperi_error_max', 'tconj', 'tconj_error_min',\n",
            "       'tconj_error_max', 'tzero_tr', 'tzero_tr_error_min',\n",
            "       'tzero_tr_error_max', 'tzero_tr_sec', 'tzero_tr_sec_error_min',\n",
            "       'tzero_tr_sec_error_max', 'lambda_angle', 'lambda_angle_error_min',\n",
            "       'lambda_angle_error_max', 'impact_parameter',\n",
            "       'impact_parameter_error_min', 'impact_parameter_error_max', 'tzero_vr',\n",
            "       'tzero_vr_error_min', 'tzero_vr_error_max', 'k', 'k_error_min',\n",
            "       'k_error_max', 'temp_calculated', 'temp_calculated_error_min',\n",
            "       'temp_calculated_error_max', 'temp_measured', 'hot_point_lon',\n",
            "       'geometric_albedo', 'geometric_albedo_error_min',\n",
            "       'geometric_albedo_error_max', 'log_g', 'publication', 'detection_type',\n",
            "       'mass_detection_type', 'radius_detection_type', 'alternate_names',\n",
            "       'molecules', 'star_name', 'ra', 'dec', 'mag_v', 'mag_i', 'mag_j',\n",
            "       'mag_h', 'mag_k', 'star_distance', 'star_distance_error_min',\n",
            "       'star_distance_error_max', 'star_metallicity',\n",
            "       'star_metallicity_error_min', 'star_metallicity_error_max', 'star_mass',\n",
            "       'star_mass_error_min', 'star_mass_error_max', 'star_radius',\n",
            "       'star_radius_error_min', 'star_radius_error_max', 'star_sp_type',\n",
            "       'star_age', 'star_age_error_min', 'star_age_error_max', 'star_teff',\n",
            "       'star_teff_error_min', 'star_teff_error_max', 'star_detected_disc',\n",
            "       'star_magnetic_field', 'star_alternate_names'],\n",
            "      dtype='object')\n",
            "0\n",
            "name          0\n",
            "mass          0\n",
            "radius        0\n",
            "discovered    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import pandas as pd\n",
        "df = pd.read_csv('exoplanet_catalog.csv')\n",
        "df.head()\n",
        "print(df.columns)\n",
        "exoplanet=df.loc[:,['# name','mass','radius','discovered']]\n",
        "new_names = ['name','mass','radius','discovered']\n",
        "exoplanet.columns = new_names\n",
        "exoplanet.dropna(inplace = True)\n",
        "print(exoplanet.duplicated().sum())\n",
        "print(exoplanet.isna().sum())\n",
        "exoplanet.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FaMkPN2EBkk"
      },
      "source": [
        "# Группировка данных\n",
        "\n",
        "Слово «анализ» означает разбор, рассмотрение с разных сторон. Анализ данных начинают с разделения их на группы по какому-нибудь признаку. Эта операция называется группировка данных. Она помогает изучить материал более подробно, чтобы затем перейти к поиску взаимосвязей между отдельными группами.\n",
        "\n",
        "\n",
        "Группировка оправданна, если данные чётко делятся по значимому признаку, а полученные группы близки к теме задачи. Например, когда есть данные обо всех покупках в супермаркете, можно смело заниматься группировкой. Так можно установить время наплыва покупателей и решить проблему пиковых нагрузок. Или посчитать средний чек — обычно для магазинов это ключевая метрика.\n",
        "\n",
        "\n",
        "Стадии группировки хорошо укладываются в словесную формулу **split-apply-combine**:\n",
        "\n",
        "•\tразделить, **split** — разбиение на группы по определённому критерию;\n",
        "\n",
        "•\tприменить, **apply** — применение какого-либо метода к каждой группе в отдельности, например, подсчёт численности группы методом count() или суммирование вызовом sum();\n",
        "\n",
        "•\tобъединить, **combine** — сведение результатов в новую структуру данных, в зависимости от условий разделения и выполнения метода это бывает DataFrame и Series.\n",
        "\n",
        "В библиотеке Pandas есть отличные инструменты группировки. Рассмотрим обращение с ними на примере анализа данных о планетах за пределами Солнечной системы, или экзопланетах. Орбитальные обсерватории засекли уже тысячи таких небесных тел. Их выявляют на снимках космических телескопов наши коллеги, аналитики данных. Поищем среди экзопланет похожие на Землю. Возможно, это наши будущие колонии, или там уже обитают разумные существа, с которыми однажды предстоит установить контакт.\n",
        "\n",
        "DataFrame с данными по нескольким тысячам экзопланет сохранён в переменной **exoplanet**. Посмотрим на первые 30 строк таблицы:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQyEHJtOEBkk",
        "outputId": "696957fe-3486-4664-f13a-5b240f619a9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                name      mass  radius  discovered\n",
            "0        1RXS 1609 b  14.00000  1.7000      2008.0\n",
            "1       2M 0122-24 b  20.00000  1.0000      2013.0\n",
            "2       2M 0219-39 b  13.90000  1.4400      2015.0\n",
            "3       2M 2140+16 b  20.00000  0.9200      2010.0\n",
            "4       2M 2206-20 b  30.00000  1.3000      2010.0\n",
            "5          2M1510A a  40.00000  1.5700      2020.0\n",
            "6          2M1510A b  39.30000  1.5700      2020.0\n",
            "7   2MASS J0348-6022  43.00000  0.9100      2021.0\n",
            "8   2MASS J0407+1546  67.00000  0.9700      2021.0\n",
            "9   2MASS J1219+3128  49.00000  0.9700      2021.0\n",
            "10          51 Eri b   2.60000  1.1100      2015.0\n",
            "11          51 Peg b   0.47000  1.9000      1995.0\n",
            "12          55 Cnc e   0.02703  0.1737      2004.0\n",
            "13         AD 3116 b  54.20000  1.0200      2017.0\n",
            "14          AU Mic b   0.05300  0.3908      2020.0\n",
            "15          AU Mic c   0.04630  0.3131      2020.0\n",
            "16       BD+20 594 b   0.07000  0.2300      2016.0\n",
            "17      COCONUTS-2 b   6.40000  1.1200      2021.0\n",
            "18          CT Cha b  17.00000  2.2000      2008.0\n",
            "19         CoRoT-1 b   1.03000  1.4900      2007.0\n",
            "20        CoRoT-10 b   2.75000  0.9700      2010.0\n",
            "21        CoRoT-11 b   2.33000  1.4300      2010.0\n",
            "22        CoRoT-12 b   0.91700  1.4400      2010.0\n",
            "23        CoRoT-13 b   1.30800  0.8850      2010.0\n",
            "24        CoRoT-14 b   7.60000  1.0900      2010.0\n",
            "25        CoRoT-15 b  63.40000  1.1200      2010.0\n",
            "26        CoRoT-16 b   0.53500  1.1700      2010.0\n",
            "27        CoRoT-17 b   2.43000  1.0200      2010.0\n",
            "28        CoRoT-18 b   3.47000  1.3100      2011.0\n",
            "29        CoRoT-19 b   1.11000  1.2900      2011.0\n"
          ]
        }
      ],
      "source": [
        "print(exoplanet.head(30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0kxMQ62EBkk"
      },
      "source": [
        "**Документация**\n",
        "\n",
        "Столбцы:\n",
        "\n",
        "•\tname: название экзопланеты;\n",
        "\n",
        "•\tmass: масса в массах планеты Юпитер;\n",
        "\n",
        "•\tradius: радиус, пересчитанный в радиусах Земли;\n",
        "\n",
        "•\tdiscovered: год открытия экзопланеты.\n",
        "\n",
        "*Источник: каталог экзопланет на портале exoplanet.eu*\n",
        "\n",
        "На картинке изображен принцип **split-apply-combine** для таблицы с экзопланетами. Посмотрим, как вообще идут дела с поиском экзопланет. Сначала данные делят по группам, где каждая группа — это год. Потом метод **count()** подсчитывает численность каждой группы. В итоге получаем новую структуру данных с группами, где каждая содержит год и число открытых за этот год экзопланет.\n",
        "\n",
        "\n",
        "\n",
        "В Рandas для группировки данных есть метод **groupby()**. Он принимает как аргумент название столбца, по которому нужно группировать. В случае с делением экзопланет по годам открытия:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyY_04lvEBkl"
      },
      "source": [
        "**print(exoplanet.groupby('discovered'))**\n",
        "\n",
        "**<pandas.core.groupby.DataFrameGroupBy object at 0x7fc1e1ca3400>**\n",
        "\n",
        "\n",
        "Применение метода **groupby()** к объекту типа DataFrame приводит к созданию объекта особого типа — **DataFrameGroupBy**. Это сгруппированные данные. Если применить к ним какой-нибудь метод Pandas, они станут новой структурой данных типа **DataFrame** или **Series**.\n",
        "Подсчитаем сгруппированные по годам экзопланеты методом **count()**:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nedViQM9EBkl",
        "outputId": "70ff3006-e9e6-4f3c-dfcb-10015c5deb69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            name  mass  radius\n",
            "discovered                    \n",
            "1995.0         1     1       1\n",
            "1996.0         1     1       1\n",
            "1999.0         1     1       1\n",
            "2000.0         2     2       2\n",
            "2001.0         1     1       1\n",
            "2002.0         1     1       1\n",
            "2004.0         7     7       7\n",
            "2005.0         4     4       4\n",
            "2006.0        10    10      10\n",
            "2007.0        19    19      19\n",
            "2008.0        25    25      25\n",
            "2009.0        15    15      15\n",
            "2010.0        57    57      57\n",
            "2011.0        96    96      96\n",
            "2012.0        73    73      73\n",
            "2013.0        96    96      96\n",
            "2014.0       105   105     105\n",
            "2015.0        57    57      57\n",
            "2016.0       106   106     106\n",
            "2017.0        63    63      63\n",
            "2018.0       114   114     114\n",
            "2019.0        71    71      71\n",
            "2020.0        88    88      88\n",
            "2021.0        42    42      42\n"
          ]
        }
      ],
      "source": [
        "print(exoplanet.groupby('discovered').count())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUZT3vAxEBkl"
      },
      "source": [
        "Если нужно сравнить наблюдения по одному показателю, метод применяют к **DataFrameGroupBy** с указанием на один столбец. Нас в первую очередь интересует радиус экзопланет: мы ищем другую Землю. Давайте получим таблицу с единственным столбцом 'radius':\n",
        "\n",
        "**exo_number = exoplanet.groupby('discovered')['radius'].count()**\n",
        "\n",
        "**print(exo_number)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XJzEKMmEBkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757e7cc9-b037-45e0-aa65-5f68a467b1fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "discovered\n",
            "1995.0      1\n",
            "1996.0      1\n",
            "1999.0      1\n",
            "2000.0      2\n",
            "2001.0      1\n",
            "2002.0      1\n",
            "2004.0      7\n",
            "2005.0      4\n",
            "2006.0     10\n",
            "2007.0     19\n",
            "2008.0     25\n",
            "2009.0     15\n",
            "2010.0     57\n",
            "2011.0     96\n",
            "2012.0     73\n",
            "2013.0     96\n",
            "2014.0    105\n",
            "2015.0     57\n",
            "2016.0    106\n",
            "2017.0     63\n",
            "2018.0    114\n",
            "2019.0     71\n",
            "2020.0     88\n",
            "2021.0     42\n",
            "Name: radius, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "exo_number = exoplanet.groupby('discovered')['radius'].count()\n",
        "\n",
        "print(exo_number)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfuB77PdEBkl"
      },
      "source": [
        "Получили Series, где по годам открытия расписано количество экзопланет, для которых удалось установить радиус.\n",
        "\n",
        "Посмотрим, как меняется средний радиус открытых экзопланет год от года. Для этого надо сложить радиусы планет, открытых за определённый год, и поделить на их количество (которое мы уже нашли).\n",
        "\n",
        "Сумма радиусов считается методом **sum()**:\n",
        "\n",
        "**exo_radius_sum = exoplanet.groupby('discovered')['radius'].sum()**\n",
        "\n",
        "\n",
        "**print(exo_radius_sum)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huZO5UZEEBkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39422188-bd8f-4e5f-b127-1278c6eeab17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "discovered\n",
            "1995.0     1.900000\n",
            "1996.0     1.060000\n",
            "1999.0     1.380000\n",
            "2000.0     2.007000\n",
            "2001.0     0.921000\n",
            "2002.0     1.200000\n",
            "2004.0     6.789700\n",
            "2005.0     4.789000\n",
            "2006.0    20.355000\n",
            "2007.0    24.334600\n",
            "2008.0    34.329000\n",
            "2009.0    15.366794\n",
            "2010.0    56.828660\n",
            "2011.0    77.967374\n",
            "2012.0    50.074507\n",
            "2013.0    69.372100\n",
            "2014.0    55.268000\n",
            "2015.0    52.684740\n",
            "2016.0    97.986000\n",
            "2017.0    51.597620\n",
            "2018.0    90.195760\n",
            "2019.0    62.114410\n",
            "2020.0    65.119180\n",
            "2021.0    31.915760\n",
            "Name: radius, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "exo_radius_sum = exoplanet.groupby('discovered')['radius'].sum()\n",
        "\n",
        "print(exo_radius_sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Q98PLGEBkl"
      },
      "source": [
        "Очень кстати, что объекты Series можно делить друг на друга. Это позволит нам разделить перечень сумм радиусов на перечень количеств экзопланет без перебора в цикле:\n",
        "\n",
        "\n",
        "**exo_radius_mean = exo_radius_sum/exo_number**\n",
        "\n",
        "**print(exo_radius_mean)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnIdTSELEBkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "374088d8-fb28-48b6-8f32-1776fb3451b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "discovered\n",
            "1995.0    1.900000\n",
            "1996.0    1.060000\n",
            "1999.0    1.380000\n",
            "2000.0    1.003500\n",
            "2001.0    0.921000\n",
            "2002.0    1.200000\n",
            "2004.0    0.969957\n",
            "2005.0    1.197250\n",
            "2006.0    2.035500\n",
            "2007.0    1.280768\n",
            "2008.0    1.373160\n",
            "2009.0    1.024453\n",
            "2010.0    0.996994\n",
            "2011.0    0.812160\n",
            "2012.0    0.685952\n",
            "2013.0    0.722626\n",
            "2014.0    0.526362\n",
            "2015.0    0.924294\n",
            "2016.0    0.924396\n",
            "2017.0    0.819010\n",
            "2018.0    0.791191\n",
            "2019.0    0.874851\n",
            "2020.0    0.739991\n",
            "2021.0    0.759899\n",
            "Name: radius, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "exo_radius_mean = exo_radius_sum/exo_number\n",
        "\n",
        "print(exo_radius_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgNx17B8EBkl"
      },
      "source": [
        "Точность наших приборов растёт, и новые экзопланеты по размерам всё ближе к Земле.\n",
        "\n",
        "А теперь вернемся к анализу датафрейма с музыкльными предпочтениями слушателей Яндекс.Музыки. Идею объединения сервисов Музыка и Радио тестировали на небольшой группе пользователей. Результаты сведены в csv-файл, который вам предстоит изучить. Итог анализа таких данных — это метрики: величины, значения которых отражают пользовательские впечатления. Одна из важнейших — **happiness**. Здесь это среднее время, которое пользователь слушает музыку в течение выбранного периода времени (в нашей задаче — за сутки). Чем дольше пользователь слушает музыку, тем он довольнее. Ваша задача: найти значение happiness и посмотреть, как оно менялось.\n",
        "\n",
        "Тем же методом **groupby()**, которым мы ищем новую Землю, можно поискать и необыкновенного человека в данных Яндекс.Музыки. Тем более, что без этого не выполнить поставленной менеджером задачи.\n",
        "\n",
        "Прежде, чем рассчитывать метрику happiness, нужно изучить пользователей, чьё «счастье» мы собираемся оценить. Какие они, эти люди, которые слушают действительно много музыки? Есть ли у них особые предпочтения, или они потребляют всё подряд?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inE7RbS4EBkm"
      },
      "source": [
        "## Задача\n",
        "\n",
        "1. Меломаны у нас есть. Сейчас узнаем идентификатор **user_id** одного из них. Для этого сгруппируем данные по каждому пользователю, чтобы собрать жанры прослушанных им композиций.\n",
        "\n",
        "Сгруппируйте DataFrame по столбцу user_id, сохраните полученный результат в переменной genre_grouping.\n",
        "\n",
        "Посчитайте количество жанров, которые выбрали пользователи, методом count(), указав, что выбираем один столбец genre_name.\n",
        "\n",
        "Сохраните результат в переменной genre_counting и выведите первые 30 строк этой таблицы.\n",
        "\n",
        "2. Быть может, те, кто за день слушает больше 50 песен, имеют более широкие предпочтения. Чтобы найти такого, изготовим универсальный инструмент.\n",
        "\n",
        "Напишите функцию user_genres, которая принимает некую группировку как свой аргумент group. Функция должна перебирать группы, входящие в эту группировку.\n",
        "\n",
        "В каждой группе два элемента — имя группы с индексом 0 и список значений с индексом 1.\n",
        "\n",
        "Обнаружив такую группу, в которой список (элемент с индексом 1) содержит более 50 значений, функция возвращает имя группы (значение элемента с индексом 0).\n",
        "\n",
        "3. Вызовите функцию **user_genres**, как аргумент передайте ей **genre_grouping**. Результат – **user_id** неведомого нам любителя музыки – сохраните в переменной **search_id** и выведите значение на экран.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7KOvLy_EBkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec06442-a511-443a-dfa7-7ac39110ed01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n",
            "Index(['user_id', 'track_name', 'artist_name', 'genre_name', 'city',\n",
            "       'total_play_seconds', 'day'],\n",
            "      dtype='object')\n",
            "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x788ea37b9b10>\n",
            "user_id\n",
            "10004220    3\n",
            "100173ED    1\n",
            "1001CE90    7\n",
            "1002410A    3\n",
            "100261F9    2\n",
            "1004AAE6    1\n",
            "1004C5D8    1\n",
            "1005BECA    1\n",
            "10089377    3\n",
            "100AB021    1\n",
            "100ACFBC    1\n",
            "10101201    2\n",
            "10107FC7    2\n",
            "10112F4C    2\n",
            "1016144E    1\n",
            "1016C39F    2\n",
            "10180175    1\n",
            "101861D1    2\n",
            "10189D10    8\n",
            "101AAA19    1\n",
            "101B046A    2\n",
            "101B53F1    1\n",
            "101BBC61    1\n",
            "101C12A4    2\n",
            "101D714C    1\n",
            "101E910F    1\n",
            "10211433    1\n",
            "10222F55    1\n",
            "1022B77E    1\n",
            "10246DCB    2\n",
            "Name: genre_name, dtype: int64\n",
            "['7D166C63']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-a4ae9b783bf8>:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  search_id = genre_grouping.apply(user_genres).dropna().tolist()\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "#1\n",
        "import pandas as pd\n",
        "df = pd.read_csv('yandex_musi.csv')\n",
        "print(df.columns)\n",
        "new_names = ['user_id','track_name',  'artist_name','genre_name','city','total_play_seconds','day']\n",
        "df.columns = new_names\n",
        "genre_name=df['genre_name']\n",
        "df['track_name']=df['track_name'].fillna('unknown')\n",
        "df['artist_name']=df['artist_name'].fillna('unknown')\n",
        "df.dropna(subset=['genre_name'], inplace=True)\n",
        "print(df.columns)\n",
        "genre_grouping=df.groupby('user_id')\n",
        "print(genre_grouping)\n",
        "genre_counting=genre_grouping['genre_name'].count()\n",
        "print(genre_counting.head(30))\n",
        "#2\n",
        "def user_genres(group):\n",
        "    count = len(group)\n",
        "    if count > 50:\n",
        "        return group.name\n",
        "#3\n",
        "\n",
        "search_id = genre_grouping.apply(user_genres).dropna().tolist()\n",
        "print(search_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUeNk1eOEBkm"
      },
      "source": [
        "# Сортировка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJHfcQ2wEBkm"
      },
      "source": [
        "Поиск необычного в группе — что среди планет, что среди меломанов — это прежде всего поиск чемпионов: объектов с выдающимися показателями по разным статьям. Как всю таблицу, так и отдельные группы изучают, сортируя строки по какому-либо столбцу.\n",
        "\n",
        "В Pandas для этой операции есть метод **sort_values()**. У него два аргумента:\n",
        "\n",
        "• **by = 'имя столбца'** — имя столбца, по которому нужно сортировать;\n",
        "\n",
        "• **ascending:** по умолчанию True. Для сортировки по убыванию установите значение False.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Среди экзопланет интересны близкие по размерам к Земле. Есть ли такие? Отсортируем список по радиусу в порядке возрастания. Тогда в голове таблицы окажутся самые малые, на которых гравитация не прижмёт нас к полу.\n",
        "\n",
        "**print(exoplanet.sort_values(by='radius').head(30))**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4I9Osv9EBkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f56490-882f-4dbc-9630-76397cfb779b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             name      mass   radius  discovered\n",
            "559   Kepler-37 b  0.010000  0.02600      2013.0\n",
            "432  Kepler-102 b  0.013530  0.04200      2014.0\n",
            "470  Kepler-138 b  0.000210  0.04700      2014.0\n",
            "654   Kepler-62 c  0.013000  0.04800      2013.0\n",
            "589   Kepler-42 d  0.003000  0.05100      2011.0\n",
            "433  Kepler-102 c  0.009440  0.05200      2014.0\n",
            "345      K2-266 c  0.000910  0.06300      2018.0\n",
            "588   Kepler-42 c  0.006000  0.06500      2011.0\n",
            "560   Kepler-37 c  0.037760  0.06700      2013.0\n",
            "851  TRAPPIST-1 h  0.001041  0.06740      2017.0\n",
            "422      KOI-55 b  0.001400  0.06800      2011.0\n",
            "847  TRAPPIST-1 d  0.001300  0.06890      2016.0\n",
            "587   Kepler-42 b  0.009000  0.07000      2011.0\n",
            "572  Kepler-408 b  0.015730  0.07300      2014.0\n",
            "441  Kepler-106 b  0.016680  0.07300      2014.0\n",
            "469  Kepler-131 c  0.026000  0.07500      2014.0\n",
            "570  Kepler-406 c  0.009000  0.07600      2014.0\n",
            "500   Kepler-20 e  0.009700  0.07700      2011.0\n",
            "447  Kepler-107 d  0.011960  0.07700      2014.0\n",
            "423      KOI-55 c  0.002100  0.07700      2011.0\n",
            "436  Kepler-102 f  0.016360  0.07900      2014.0\n",
            "298      K2-137 b  0.500000  0.07900      2017.0\n",
            "73       GJ 143 c  0.011640  0.07958      2018.0\n",
            "848  TRAPPIST-1 e  0.002000  0.08190      2017.0\n",
            "663   Kepler-68 c  0.006420  0.08270      2013.0\n",
            "443  Kepler-106 d  0.025490  0.08500      2014.0\n",
            "332      K2-239 c  0.002800  0.08900      2018.0\n",
            "501   Kepler-20 f  0.045000  0.08900      2011.0\n",
            "648  Kepler-595 c  0.010380  0.09000      2020.0\n",
            "372       K2-32 e  0.006600  0.09000      2019.0\n"
          ]
        }
      ],
      "source": [
        "print(exoplanet.sort_values(by='radius').head(30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6blEjXWhEBkm"
      },
      "source": [
        "Оказывается, некоторые из уже открытых экзопланет по размерам близки не то что к Земле, но уже и к Луне! Получим список экзопланет с радиусом меньше земного. Смотрите, как логический оператор (здесь это <) задействуется в отборе элементов столбца. Дальше нам этот приём не раз понадобится.\n",
        "\n",
        "\n",
        "**print(exoplanet[exoplanet['radius'] < 1])**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jgmHn8gEBkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f022540a-3f36-412a-e85e-69673a5323cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  name      mass   radius  discovered\n",
            "3         2M 2140+16 b  20.00000  0.92000      2010.0\n",
            "7     2MASS J0348-6022  43.00000  0.91000      2021.0\n",
            "8     2MASS J0407+1546  67.00000  0.97000      2021.0\n",
            "9     2MASS J1219+3128  49.00000  0.97000      2021.0\n",
            "12            55 Cnc e   0.02703  0.17370      2004.0\n",
            "...                ...       ...      ...         ...\n",
            "1036  WISE 1217+16 A b  22.00000  0.96000      2012.0\n",
            "1041        Wolf 940 b  26.00000  0.92000      2009.0\n",
            "1043           XO-2N b   0.62000  0.97300      2007.0\n",
            "1049  ZTF J0038+2030 b  59.30000  0.78300      2021.0\n",
            "1053          pi Men c   0.01517  0.16719      2018.0\n",
            "\n",
            "[565 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "print(exoplanet[exoplanet['radius'] < 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8PF4A_HEBkm"
      },
      "source": [
        "Но и этот список такой длинный, что изучать его лучше по частям. Экзопланеты, близкие по размерам к Земле, за последнее десятилетие открывали нередко. Можно изучать список открытых за каждый год. Например, для 2014 года (вновь обратите внимание на работу логического оператора, теперь это ==):\n",
        "\n",
        "**print(exoplanet[exoplanet['discovered'] == 2014])**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FRKcm-yEBkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08095558-a5d5-41c9-ca28-5cbba1dc33b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             name    mass  radius  discovered\n",
            "86       GU Psc b  11.000   1.350      2014.0\n",
            "130    HAT-P-49 b   1.730   1.413      2014.0\n",
            "136    HAT-P-54 b   0.760   0.944      2014.0\n",
            "163     HATS-15 b   2.170   1.105      2014.0\n",
            "190      HATS-4 b   1.323   1.020      2014.0\n",
            "...           ...     ...     ...         ...\n",
            "1010    WASP-74 b   0.826   1.248      2014.0\n",
            "1020    WASP-83 b   0.300   1.040      2014.0\n",
            "1023  WASP-87 A b   2.210   1.385      2014.0\n",
            "1025    WASP-89 b   5.900   1.040      2014.0\n",
            "1030  WASP-94 A b   0.452   1.720      2014.0\n",
            "\n",
            "[105 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "print(exoplanet[exoplanet['discovered'] == 2014])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkTxOTa3EBkm"
      },
      "source": [
        "А чтобы не тратить время на лишнее, поставим оба условия сразу. Для этого в Pandas есть логический оператор &, подобный оператору and языка Python. Напомним, его смысл на русском языке можно передать словами «и ещё»:\n",
        "\n",
        "**# экзопланеты меньше Земли __ и ещё __ открытые в 2014 году**\n",
        "\n",
        "**exo_small_14 = exoplanet[ (exoplanet['radius']<1) & (exoplanet['discovered']==2014)]**\n",
        "\n",
        "**print(exo_small_14)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQ3UcFhhEBkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d517e1f7-7852-46e0-f575-802b5f116933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             name    mass  radius  discovered\n",
            "136    HAT-P-54 b  0.7600   0.944      2014.0\n",
            "201      HATS-5 b  0.2370   0.912      2014.0\n",
            "212      HATS-6 b  0.3190   0.998      2014.0\n",
            "269  HIP 116454 b  0.0372   0.226      2014.0\n",
            "412    KOI-1257 b  1.4500   0.940      2014.0\n",
            "..            ...     ...     ...         ...\n",
            "698   Kepler-95 b  0.0410   0.305      2014.0\n",
            "699   Kepler-96 b  0.0270   0.238      2014.0\n",
            "700   Kepler-97 b  0.0110   0.132      2014.0\n",
            "701   Kepler-98 b  0.0110   0.178      2014.0\n",
            "702   Kepler-99 b  0.0190   0.132      2014.0\n",
            "\n",
            "[78 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "exo_small_14 = exoplanet[ (exoplanet['radius']<1) & (exoplanet['discovered']==2014)]\n",
        "\n",
        "print(exo_small_14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8COU4qE-EBkm"
      },
      "source": [
        "Отсортируем результат в порядке убывания радиуса.\n",
        "\n",
        "**print(exo_small_14.sort_values(by = 'radius', ascending = False))**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD4Cq5pAEBkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94867e32-c852-40c7-8b92-d03e457e9ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             name     mass  radius  discovered\n",
            "212      HATS-6 b  0.31900   0.998      2014.0\n",
            "593  Kepler-425 b  0.25000   0.978      2014.0\n",
            "586  Kepler-419 b  2.50000   0.960      2014.0\n",
            "136    HAT-P-54 b  0.76000   0.944      2014.0\n",
            "412    KOI-1257 b  1.45000   0.940      2014.0\n",
            "..            ...      ...     ...         ...\n",
            "572  Kepler-408 b  0.01573   0.073      2014.0\n",
            "441  Kepler-106 b  0.01668   0.073      2014.0\n",
            "433  Kepler-102 c  0.00944   0.052      2014.0\n",
            "470  Kepler-138 b  0.00021   0.047      2014.0\n",
            "432  Kepler-102 b  0.01353   0.042      2014.0\n",
            "\n",
            "[78 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "print(exo_small_14.sort_values(by = 'radius', ascending = False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckN7fugDEBkm"
      },
      "source": [
        "Самая крупная планета, Kepler 106 d – почти как Земля, вращается вокруг звезды Kepler 106 в созвездии Лебедя. Эта звезда очень похожа на наше Солнце. Правда, до неё 1435 световых лет — далековато. Но, возможно, учёные что-нибудь придумают. А мы пока применим эту технологию к нашему бизнесу, в «приземлённой» задаче.\n",
        "## Задача\n",
        "\n",
        "1. Космический телескоп Kepler открыл похожую на Землю планету у похожей на Солнце звезды. А вы в данных Яндекс.Музыки обнаружили меломана с уникальными данными. Он за день послушал больше 50 композиций.\n",
        "Получите таблицу с прослушанными им треками.\n",
        "\n",
        "Для этого запросите из структуры данных df строки, отвечающие сразу двум условиям:\n",
        "\n",
        "1) значение в столбце 'user_id' должно быть равно значению переменной search_id;\n",
        "\n",
        "2) время прослушивания, т.е. значение в столбце 'total_play_seconds', не должно равняться 0.\n",
        "\n",
        "Сохраните результат в переменной music_user.\n",
        "\n",
        "2. Теперь узнаем, сколько времени он слушал музыку каждого жанра.\n",
        "\n",
        "Сгруппируйте данные таблицы music_user по столбцу 'genre_name' и получите сумму значений столбца 'total_play_seconds'. Сохраните результат в переменной sum_music_user и выведите её значение на экран.\n",
        "\n",
        "3. Кажется, предпочтения нашего меломана начинают проявляться. Но, возможно, длительность композиций от жанра к жанру сильно различается. Важно знать, сколько треков каждого жанра он включил.\n",
        "\n",
        "Сгруппируйте данные по столбцу genre_name и посчитайте, сколько значений в столбце genre_name. Сохраните результат в переменной count_music_user и выведите её значение на экран.\n",
        "\n",
        "4. Чтобы предпочтения были видны сразу, нужно крупнейшие значения расположить наверху. Отсортируйте данные в группировке sum_music_user по убыванию. Внимание: когда применяете метод sort_values() к Series с единственным столбцом, аргумент by указывать не нужно, только порядок сортировки.\n",
        "\n",
        "Сохраните результат в переменной final_sum и выведите её значение на экран.\n",
        "\n",
        "5. Теперь то же самое надо сделать с числом прослушанных меломаном композиций. Отсортируйте данные группировки count_music_user по убыванию. Сохраните результат в переменной final_count, значение которой выведите на экран.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YNeBRn3EBkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "029fe198-4d86-41ed-aa0e-70ddcdb6a704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        user_id track_name artist_name  genre_name              city  \\\n",
            "274    7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "2375   7D166C63    unknown     unknown         pop  Saint-Petersburg   \n",
            "2561   7D166C63    unknown     unknown     country  Saint-Petersburg   \n",
            "3096   7D166C63    unknown     unknown    schlager  Saint-Petersburg   \n",
            "4334   7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "5671   7D166C63    unknown     unknown         pop  Saint-Petersburg   \n",
            "6498   7D166C63    unknown     unknown         pop  Saint-Petersburg   \n",
            "7187   7D166C63    unknown     unknown         pop  Saint-Petersburg   \n",
            "8388   7D166C63    unknown     unknown         pop  Saint-Petersburg   \n",
            "8906   7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "9408   7D166C63    unknown     unknown        rock  Saint-Petersburg   \n",
            "11810  7D166C63    unknown     unknown         pop  Saint-Petersburg   \n",
            "13593  7D166C63    unknown     unknown        rock  Saint-Petersburg   \n",
            "14889  7D166C63    unknown     unknown         pop  Saint-Petersburg   \n",
            "16019  7D166C63    unknown     unknown    schlager  Saint-Petersburg   \n",
            "16367  7D166C63    unknown     unknown   classical  Saint-Petersburg   \n",
            "18432  7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "18546  7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "18931  7D166C63    unknown     unknown    schlager  Saint-Petersburg   \n",
            "19184  7D166C63    unknown     unknown         pop  Saint-Petersburg   \n",
            "19196  7D166C63    unknown     unknown         pop  Saint-Petersburg   \n",
            "19805  7D166C63    unknown     unknown         pop  Saint-Petersburg   \n",
            "19957  7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "20237  7D166C63    unknown     unknown        rock  Saint-Petersburg   \n",
            "21930  7D166C63    unknown     unknown    schlager  Saint-Petersburg   \n",
            "24396  7D166C63    unknown     unknown         rnb  Saint-Petersburg   \n",
            "25888  7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "27766  7D166C63    unknown     unknown  soundtrack  Saint-Petersburg   \n",
            "27911  7D166C63    unknown     unknown      reggae  Saint-Petersburg   \n",
            "30855  7D166C63    unknown     unknown      ghazal  Saint-Petersburg   \n",
            "31435  7D166C63    unknown     unknown    schlager  Saint-Petersburg   \n",
            "32057  7D166C63    unknown     unknown        rock  Saint-Petersburg   \n",
            "36122  7D166C63    unknown     unknown       dance  Saint-Petersburg   \n",
            "37806  7D166C63    unknown     unknown       dance  Saint-Petersburg   \n",
            "38215  7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "40217  7D166C63    unknown     unknown         pop  Saint-Petersburg   \n",
            "42656  7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "43443  7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "45793  7D166C63    unknown     unknown         pop  Saint-Petersburg   \n",
            "46351  7D166C63    unknown     unknown         pop  Saint-Petersburg   \n",
            "46962  7D166C63    unknown     unknown         pop  Saint-Petersburg   \n",
            "47653  7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "48692  7D166C63    unknown     unknown         pop  Saint-Petersburg   \n",
            "49130  7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "49742  7D166C63    unknown     unknown        rock  Saint-Petersburg   \n",
            "51393  7D166C63    unknown     unknown         hip  Saint-Petersburg   \n",
            "52435  7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "54461  7D166C63    unknown     unknown        folk  Saint-Petersburg   \n",
            "56112  7D166C63    unknown     unknown    folkrock  Saint-Petersburg   \n",
            "56825  7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "57610  7D166C63    unknown     unknown        punk  Saint-Petersburg   \n",
            "59260  7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "61507  7D166C63    unknown     unknown        jazz  Saint-Petersburg   \n",
            "62391  7D166C63    unknown     unknown      reggae  Saint-Petersburg   \n",
            "\n",
            "      total_play_seconds        day  \n",
            "274             20:29:53  Wednesday  \n",
            "2375            20:34:44  Wednesday  \n",
            "2561            08:39:24     Monday  \n",
            "3096            08:42:55  Wednesday  \n",
            "4334            14:23:27     Monday  \n",
            "5671            08:46:51     Monday  \n",
            "6498            14:23:30     Monday  \n",
            "7187            08:25:33  Wednesday  \n",
            "8388            14:22:43     Monday  \n",
            "8906            14:16:10     Monday  \n",
            "9408            14:12:02     Monday  \n",
            "11810           09:04:15     Monday  \n",
            "13593           14:23:43     Monday  \n",
            "14889           20:30:23  Wednesday  \n",
            "16019           08:39:38  Wednesday  \n",
            "16367           20:26:32  Wednesday  \n",
            "18432           14:23:06     Monday  \n",
            "18546           08:39:39  Wednesday  \n",
            "18931           14:13:54     Monday  \n",
            "19184           14:10:05     Monday  \n",
            "19196           14:34:24     Monday  \n",
            "19805           08:39:48     Monday  \n",
            "19957           14:09:57     Monday  \n",
            "20237           08:35:58  Wednesday  \n",
            "21930           09:04:19     Monday  \n",
            "24396           08:32:10  Wednesday  \n",
            "25888           08:35:38  Wednesday  \n",
            "27766           14:09:56     Monday  \n",
            "27911           08:46:55     Monday  \n",
            "30855           08:32:18  Wednesday  \n",
            "31435           08:35:45  Wednesday  \n",
            "32057           08:56:30     Monday  \n",
            "36122           14:11:56     Monday  \n",
            "37806           14:23:32     Monday  \n",
            "38215           08:47:08     Monday  \n",
            "40217           14:23:01     Monday  \n",
            "42656           14:06:29     Monday  \n",
            "43443           14:12:40     Monday  \n",
            "45793           20:16:38  Wednesday  \n",
            "46351           14:09:37     Monday  \n",
            "46962           08:39:48     Monday  \n",
            "47653           20:29:59  Wednesday  \n",
            "48692           14:23:30     Monday  \n",
            "49130           08:56:35     Monday  \n",
            "49742           08:35:58  Wednesday  \n",
            "51393           20:29:56  Wednesday  \n",
            "52435           08:42:54  Wednesday  \n",
            "54461           13:52:18     Monday  \n",
            "56112           14:29:08     Monday  \n",
            "56825           08:47:03     Monday  \n",
            "57610           13:52:12     Monday  \n",
            "59260           14:28:36     Monday  \n",
            "61507           20:30:15  Wednesday  \n",
            "62391           09:04:14     Monday  \n",
            "genre_name\n",
            "pop           20:34:4408:46:5114:23:3008:25:3314:22:4309:04:...\n",
            "hip                                                    20:29:56\n",
            "jazz          20:29:5314:23:2714:16:1014:23:0608:39:3914:09:...\n",
            "classical                                              20:26:32\n",
            "folkrock                                               14:29:08\n",
            "rock                   14:12:0214:23:4308:35:5808:56:3008:35:58\n",
            "dance                                          14:11:5614:23:32\n",
            "soundtrack                                             14:09:56\n",
            "folk                                                   13:52:18\n",
            "punk                                                   13:52:12\n",
            "reggae                                         08:46:5509:04:14\n",
            "schlager               08:42:5508:39:3814:13:5409:04:1908:35:45\n",
            "country                                                08:39:24\n",
            "ghazal                                                 08:32:18\n",
            "rnb                                                    08:32:10\n",
            "Name: total_play_seconds, dtype: object\n",
            "genre_name\n",
            "rnb                                                    08:32:10\n",
            "ghazal                                                 08:32:18\n",
            "country                                                08:39:24\n",
            "schlager               08:42:5508:39:3814:13:5409:04:1908:35:45\n",
            "reggae                                         08:46:5509:04:14\n",
            "punk                                                   13:52:12\n",
            "folk                                                   13:52:18\n",
            "soundtrack                                             14:09:56\n",
            "dance                                          14:11:5614:23:32\n",
            "rock                   14:12:0214:23:4308:35:5808:56:3008:35:58\n",
            "folkrock                                               14:29:08\n",
            "classical                                              20:26:32\n",
            "jazz          20:29:5314:23:2714:16:1014:23:0608:39:3914:09:...\n",
            "hip                                                    20:29:56\n",
            "pop           20:34:4408:46:5114:23:3008:25:3314:22:4309:04:...\n",
            "Name: total_play_seconds, dtype: object\n",
            "        user_id                  track_name     artist_name genre_name  \\\n",
            "2        20EC38           Funiculì funiculà     Mario Lanza        pop   \n",
            "14     94EB25C2  Make Love Whenever You Can       Arabesque        pop   \n",
            "174    1CA0CEFB  Atlanta Misses You Tonight          Katiah        pop   \n",
            "360    18B3FE7D                   Fine Girl          ZieZie        pop   \n",
            "365    2A68D62C                        Oups        Mermonte        pop   \n",
            "...         ...                         ...             ...        ...   \n",
            "64640  EE6A6D66                   Two Shots     Goody Grace        pop   \n",
            "64753  A129C34D              Flames of Love         m@rcell        pop   \n",
            "64802  2C554319                      Adagio   Le Dolce Vita        pop   \n",
            "64962  E7DF6780             I Got the Blues     Glen Morris        pop   \n",
            "65004  1D4AE81E                   War Paint  Frankie Simone        pop   \n",
            "\n",
            "                   city total_play_seconds        day  \n",
            "2      Saint-Petersburg           20:58:07  Wednesday  \n",
            "14     Saint-Petersburg           13:22:08  Wednesday  \n",
            "174    Saint-Petersburg           20:25:45  Wednesday  \n",
            "360    Saint-Petersburg           13:22:38  Wednesday  \n",
            "365    Saint-Petersburg           09:30:41  Wednesday  \n",
            "...                 ...                ...        ...  \n",
            "64640  Saint-Petersburg           14:14:48  Wednesday  \n",
            "64753  Saint-Petersburg           09:12:42  Wednesday  \n",
            "64802  Saint-Petersburg           14:56:57  Wednesday  \n",
            "64962  Saint-Petersburg           14:50:48  Wednesday  \n",
            "65004  Saint-Petersburg           20:10:11  Wednesday  \n",
            "\n",
            "[1003 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "music_user=df[ (df['user_id'].isin(search_id))&(df['total_play_seconds']!= 0)]\n",
        "print(music_user)\n",
        "sum_music_user = music_user.groupby('genre_name')['total_play_seconds'].sum()\n",
        "final_sum  = sum_music_user.sort_values(ascending=False)\n",
        "final_count = sum_music_user.sort_values(ascending=True)\n",
        "print(final_sum)\n",
        "\n",
        "print(final_count)\n",
        "\n",
        "x=df[ (df['genre_name']=='pop')&(df['city']=='Saint-Petersburg')&(df['day']=='Wednesday')]\n",
        "print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87ceb7vQEBkm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}